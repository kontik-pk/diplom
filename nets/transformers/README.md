## Conformer

В сверточной нейронной сети (_CNN_) операции свертки хороши для извлечения локальных признаков, но плохо справляются с составлением глобального представления, генерализацией. В трансформерах каскадные _self-attention_ модули могут фиксировать зависимости признаков на большом расстоянии, но, к сожалению, ухудшают детализацию локальных элементов.
Авторы статьи [Conformer: Local Features Coupling Global Representations for Visual Recognition](https://arxiv.org/pdf/2105.03889v1.pdf) представляют новую гибридную архитектуру нейронной сети, которая объединяет достоинства сверточных сетей и трансформеров. 

В настоящее время, различные реализации трансформеров активно используются для решения задач компьютерного зрения. 
Метод _ViT_ (_visual transformer_)[16] создает последовательность токенов путем разделения каждого изображения на фрагменты с учетом местоположения и применяет каскадные блоки 
трансформера для извлечения параметризованных векторов в качестве визуальных представлений. Благодаря механизму _self-attention_ и структуре 
многослойного персептрона (_MLP_), _visual transformer_ отражает сложные пространственные преобразования и зависимости признаков на большом расстоянии, 
которые составляют глобальные представления. К сожалению, _visual transformer_ не восприимчив к локальным особенностям признаков, что приводит к снижению различимости фона и переднего плана. 
Улучшенные вариации _visual transformer_ используют модуль токенизации или карты функций _CNN_ в качестве входных токенов для захвата информации о соседних элементах. 
Тем не менее, вопрос остается открытым, каким образом наиболее оптимально распознавать локальные признаки, не теряя глобального представления об объекте.

Архитектура гибридной нейронной сети `Conformer` содержит две ветви: первая ветвь представляет собой сверточную нейронную сеть семейства `ResNet`, а вторая - нейронная сеть семейства `ViT`.
Ветви соединены между собой элементыми _Feature Coupling Unit (FCU)_. Основная цель этих элементов - обеспечить обмен семантической информацией между блоками сетей этих ветвей. 
Элементы _FCU_ разработаны с учетом размерности карт признаков _CNN_ и выхода трансформера: _FCU_ используют свертку 1×1 для определения количества каналов,
стратегии _down/up sampling_ для определения разрешения карты признаков, _LayerNorm_ и _BatchNorm_ для нормализации значений признаков. Поскольку _CNN_ и трансформер имеют тенденцию 
распознавать признаки на разных уровнях (локальный или глобальный), _FCU_ вставляется в каждый блок, чтобы последовательно устранить семантическое 
расхождение между ними в интерактивном режиме. Такая процедура слияния может значительно повысить способность глобального восприятия локальных признаков и распознавание локальных деталей в глобальных представлениях.

**Figure 1: Comparison of feature maps of CNN (ResNet-101) [18], Visual Transformer (DeiT-S)**

На Рисунке 1 отображена способность нейросетевой модели `Conformer` различать локальные признаки и составлять глобальное представление по сравнению с обычными _CNN_ и трансформерами. В то время как обычные _CNN_ (например, `ResNet-101`) имеют тенденцию улавливать 
отличительные локальные области (например, голову или хвост павлина),  ветвь _CNN_ модели `Conformer` может активировать весь экстент объекта (рис. 1 (b) и (f)). При использовании только трансформеров для слабо-различимых локальных особенностей (например, размытых границ объекта) 
трудно отличить объект от фона (рис. 1 (c) и (g)). Связь локальных признаков и глобального представления значительно повышает различимость признаков, полученных только с помощью трансформера (рис. 1 (d) и (h)).

Архитектура `Conformer` выглядит следующим образом (Рисунок 2):

**Figure 2: Network architecture of the proposed Conformer.**

В `Conformer` из ветви трансформера глобальное представление последовательно передается в карты признаков, чтобы усилить способность глобального восприятия ветви _CNN_. Точно так же локальные признаки из ветви _CNN_ постепенно возвращаются к эмбеддингам трансформера, чтобы обогатить локальные детали его ветви. 
`Conformer` состоит из стержневого модуля, двух ветвей, элементов _FCU_ для их соединения и двух классификаторов (слой fc) для каждой из ветвей.
Стержневой модуль представляет собой свертку 7 * 7 с шагом 2, слоем _MaxPool_ 3×3 с шагом 2. Каждая ветвь состоит из _N_ (например, 12) повторяющихся блоков свертки или трансформера. Такая параллельная структура подразумевает, что ветви _CNN_ и трансформера могут соответственно сохранять 
в максимальной степени локальные особенности и глобальные представления. _FCU_ предлагается как мостовой модуль для объединения локальных особенностей в ветви _CNN_ с глобальным представлением в ветви трансформера. 

Для каждой из ветвей есть свой классификатор. Во время обучения используется _CrossEntropyLoss_, чтобы контроллировать обучение каждой из ветвей отдельно. 
Эмпирически установлено, что важность функций потерь одинакова. Во время валидации и тестирования, выходные данные двух классификаторов просто суммируются как результаты предсказания.

## Источники

- [Conformer: Local Features Coupling Global Representations for Visual Recognition](https://arxiv.org/pdf/2105.03889v1.pdf)
