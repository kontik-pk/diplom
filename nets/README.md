# Данные

Данные для исследования взяты из соревнования на платформе _Kaggle_: https://www.kaggle.com/c/dog-breed-identification/overview/description. Обучение во всех экспериментах проводилось дважды: на исходном датасете соревнования, и на искусственно сокращенном - для того, чтобы сравнить ухудшение качества классификации при обучении на выборках разного размера. Обучающая выборка полного датасета содержит около 8К изображений, принадлежащих 120 классам. В среднем в каждом классе 64 изображения; самый многочисленный класс содержит 94 картинки, а самый малочисленный - 50.
В сокращенном датасете в каждом классе в два раза меньше картинок. Тестирование осуществлялось на закрытой тестовой выборке соревнования, результат рассчитывался по метрике _Multi Class Log Loss_ путем сабмита. 

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/logarithmic_loss_function.png" width="500" />
</div></br>
<div align="center">
</div></br>

# Сверточные нейронные сети

В данном исследовании использовались архитектуры сверточных нейросетей `VGG-19`, `ResNet-152`, `DenseNet-161`, `EfficientNet-B6`. Модели предобучены на датасете `ImageNet`. Описания архитектур представлены [здесь](https://github.com/kontik-pk/diplom/tree/main/nets/convolutional). Параметры обучения для каждой из сетей:

- Функция потерь: _CrossEntropyLoss_
- Скорость обучения: 0.00005
- Количество эпох: 10
- Оптимизатор: _AdamW_


## Обучение моделей

Результаты обучения моделей представлены в таблице:

| Model           | Params   |   Score (full)  | Score (short) | delta   |
| :-------------: |:--------:| :-------------: |:-------------:|:-------:|
| VGG-19          |   144M   |     1.01253     |    1.47443    | 0.4619  |
| ResNet-152      |    60M   |     1.18338     |    1.12304    | -0.0603 |
| DenseNet-161    |    26M   |     1.01522     |    1.46973    | 0.4545  |
| EfficientNet-B6 |    43M   |     0.84965     |    0.86976    | 0.0201  |

Лучший результат показала модель `EfficientNet-B6` - не только качество классификации лучше, но и разница между обучением на сокращенном и полном датасетах меньше, чем у остальных 
моделей, что говорит о том, что деградация результата с уменьшением обучающей выборки меньше.

Кривые обучения сверточных нейросетей на полном датасете выглядят следующим образом:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_cnn.JPG" width="700" />
</div></br>
<div align="center">
</div></br>

На сокращенном датасете:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_cnn_short.JPG" width="700" />
</div></br>
<div align="center">
</div></br>

## Дифференцированное обучение моделей

В этом эксперименте слои нейросети обучались с разной скоростью - у самых глубоких слоев скорость обучения значительно меньше (от 100 до 1000 раз). Скорость обучения постепенно нарастает от глубоких слоев к классификатору. Результаты обучения представлены в таблице:

| Model           | Params   |   Score (full)  | Score (short) | delta   |
| :-------------: |:--------:| :-------------: |:-------------:|:-------:|
| VGG-19          |   144M   |     0.86622     |    1.17212    | 0.3059  |
| ResNet-152      |    60M   |     0.72972     |    0.80292    | 0.0732  |
| DenseNet-161    |    26M   |     0.73347     |    1.04323    | 0.3098  |
| EfficientNet-B6 |    43M   |     0.89958     |    0.93136    | 0.0318  |

В целом, полученное качество выше для всех моделей по сравнению с обучением всех слоев, как на полном датасете, так и на сокращенном. Разница классификации при обучении на выборках разного размера по сравнению с предыдущим
экспериментом получилась больше только для модели `EfficientNet-B6`, но незначительно.

График функции потерь для дифференцированного обучения слоев сверточных нейросетей на полном датасете:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_diff.JPG" width="700" />
</div></br>
<div align="center">
</div></br>

На сокращенном:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_diff_short.JPG" width="700" />
</div></br>
<div align="center">
</div></br>


## Обучение моделей с использованием аугментаций

В данном эксперименте в картинкам из обучающей выборки применялись следующие аугментации:
- Изменение яркости, контрастности, насыщенности и оттенока изображения;
- Преобразование изображения в черно-белое;
- Поворот изображения по горизонтали;
- Случайное аффинное преобразование изображения на 20 градусов с сохранением инвариантности центра;
- Поворот изображения на 20 градусов;
- Вертикальный поворот изображения случайным образом.

Результаты обучения представлены в таблице:

| Model           | Params   |   Score (full)  | Score (short) | delta   |
| :-------------: |:--------:| :-------------: |:-------------:|:-------:|
| VGG-19          |   144M   |    0.90778      |   1.39809     | 0.4903  |
| ResNet-152      |    60M   |    1.01417      |   1.11357     | 0.0994  |
| DenseNet-161    |    26M   |    0.99121      |   1.39809     | 0.4067  |
| EfficientNet-B6 |    43M   |    0.71773      |   0.75062     | 0.0329  |

Кривые обучения сверточных нейронных сетей с использованием аугментаций на полном датасете:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_aug.JPG" width="700" />
</div></br>
<div align="center">
</div></br>

На сокращенном:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_aug_short.JPG" width="700" />
</div></br>
<div align="center">
</div></br>


По сравнению с результатами, полученными при обучении моделей на тренировочной выборке без применения аугментаций, качество выросло для всех моделей как на полном датасете, так и на сокращенном.

# Трансформеры

В этом эксперименте использовались архитектуры `ResT`, `CycleMLP` и `Conformer`. Описания моделей представлены [здесь](https://github.com/kontik-pk/diplom/tree/main/nets/transformers). Параметры обучения те же, что использовались для сверточных нейросетей, кроме скорости обучения - здесь она 3e<sup>-5</sup>.

## Обучение моделей

При обучении моделей на полном и сокращенном датасетах получены следующие результаты:

| Model           | Params   |   Score (full)  | Score (short) | delta   |
| :-------------: |:--------:| :-------------: |:-------------:|:-------:|
| ResT            | 30M      |   0.56123       |   0.68494     | 0.1237  |
| CycleMLP        | 76M      |   0.46992       |   0.61695     | 0.1470  |
| Conformer-B     | 83M      |   0.31189       |   0.33163     | 0.0197  |


Полученное качество значительно выше, чем при использовании сверточных нейронных сетей, как на полном датасете, так и на сокращенном. Разница между результатами, полученных на двух вариантах датасета, также меньше, чем при обучении _CNN_.

Кривые обучения трансформеров на полном датасете:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_transformers.JPG" width="700" />
</div></br>
<div align="center">
</div></br>

На сокращенном:

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/illustrations/loss_transformers_short.JPG" width="700" />
</div></br>
<div align="center">
</div></br>


