# Исследуемые модели

Ниже представлена краткая информация об используемых в данной работе архитектурах сверточных нейронных сетей.

## VGG

`VGG-19` — сверточная нейронная сеть (CNN), которая имеет 19 слоев (16 сверточных, 3 полносвязных) а также 5 слоев `MaxPool` и 1 слой `SoftMax`. Она была сконструирована и обучена в Оксфордском университете в 2014 году. Для обучения сети VGG-19 использовалось более 1 миллиона изображений из базы данных `ImageNet`. 

Сеть VGG впервые представлена в статье [Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556v6.pdf) в 2015  году. Авторы экспериментировали с глубиной сверточной сети и изучали влияние количества слоев в архитектуре на итоговое качество классификации. На вход сетям подавались изображения 224 × 224 пикселя RGB. Единственная предварительная обработка - это вычитание из каждого пикселя среднего значения RGB, вычисленного на обучающем наборе. Каждое изображение проходило через сверточные слои, размер свертки составлял 3×3 пикселя, шаг свертки - 1 пиксель. 
За сверточными слоями следует три полносвязных слоя. Первые два содержат по 4096 нейронов, а последний - 1000 нейронов (по количеству определяемых классов). Архитектура сети завершается слоем `SoftMax`. В качестве функции активации используется `ReLU`.

**Vgg19**

Обучение сети осуществлялось с помощью градиентного спуска, размер батча составлял 256 изображений. Скорость обучения изначально установлена 10<sup>2</sup>, но уменьшалась в 10 раз, как только качество классифкации на валидационной выборке переставало улучшаться. Скорость обучения уменьшалась 3 раза, а обучение остановлено на 74 эпохах. 

Авторами исследовались сети глубиной 11, 13, 16 и 19 слоев. Лучшие результаты показала самая глубокая сеть.

В настоящий момент, сеть `VGG-19` занимает 436 место по качеству классификации на датасете `ImageNet` (top 1 accuracy - 74.5%, top 5 accuracy -	92.0%). Рейтинг доступен [здесь](https://paperswithcode.com/sota/image-classification-on-imagenet).

## ResNet

`ResNet` — сокращенное название для Residual Network (дословно  — «остаточная сеть»). Сеть `ResNet` была разработана в Microsoft в 2015 году для решения задачи распознавания изображений. Эта модель также обучена на более чем 1 миллионе изображений из базы данных `ImageNet`. `ResNet` может классифицировать до 1000 объектов, принимает на вход цветные изображения размером 224×224 пикселей. Данная сеть была разработана с целью избавиться от затухающих и взрывных градиентов.

[Статья](https://arxiv.org/pdf/1512.03385v1.pdf), в которой представлена сеть `ResNet` начинается с вопроса о том, всегда ли увеличение глубины сети гарантирует лучший результат. Ответ на этот вопрос, конечно, отрицательный, поскольку увеличение количества слоев приводит к проблеме затухающих/взрывающихся градиентов. Из-за этого обучение глубоких сетей затрудняется - поскольку градиент распространяется обратно на более ранние слои, повторное умножение может сделать градиент бесконечно малым. В результате, по мере того, как сеть углубляется, качество классификации начинает быстро ухудшаться. Для решения данной проблемы, авторы предлагают использовать *остаточное обучение*, основная особенность которого - использование *остаточных блоков* (*Residual blocks*) в архитектуре модели.



<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/residual_block.png" width="400" />
</div></br>
<div align="center">
  <figcaption>Рис. 2. <i>Residual block</i> </figcaption>
</div></br>

Эмпирически показано, что нейронные с большим количеством слоев может показывать качество классификации хуже, чем сети с меньшим количеством слоев.



<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/plain_nets_training.png" width="600" />
</div></br>
<div align="center">
  <figcaption>Рис. 3. <i>Ошибка обучения (слева) и ошибка теста (справа) на CIFAR-10 с 20-слойными и 56-слойными сетями. Более глубокая сеть имеет более высокую ошибку обучения и, следовательно, ошибку на тесте.</i> </figcaption>
</div></br>



При увеличении количества слоев в нейронной сети, качество обучения растет до определенного момента, а потом начинает уменьшаться. Причиной этому может быть как переобучение (нейросеть "запоминает" признаки, что приводит к великолепным результатам на обучающей выборке, и к ухудшению качества на валидационной), так и затухание градиента. Такую проблему деградации можно решить, модифицировав процесс обучения. Архитектуры сетей до появления `ResNet` представляли собой последовательность слоев, через которые пропускается исходное изображение. После того, как исходное изображение пропустится через один слой, результат преобразования отправляется дальше, к следующему слою, и так далее. 
Идея `residual blocks` основана на том, чтобы сохранять "остаточную" информацию перед переходом к следующим слоям. Например, назовем входную матрицу `x`, а наша цель - найти оптимальное распределение весов в свертке `H(x)`. Тогда разница между входом и выходом (или остаток) будет:
```
R(x) = Output — Input = H(x) — x
```
А искомое распределение

```
H(x) = R(x) + x
```
Сети с *Residual blocks* обучать проще, и итоговое качество классификации выше. Благодаря использованию таких блоков, в некоторой степени решается проблема затухания градиента, что делает процесс обучения более тяжелых сетей эффективнее.



<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/resnet_vs_plain.png" width="600" />
</div></br>
<div align="center">
  <figcaption>Рис. 4. <i>Обучение на ImageNet. Тонкие кривые обозначают ошибку обучения, жирные кривые - ошибка на валидационной выборке. Слева: сети без Residual blocks с 18 и 34 слоями. Справа: ResNet из 18 и 34 слоев. </i> </figcaption>
</div></br>

Нейронная сеть `ResNet-152` в настоящий момент занимает 339 место в соревновании по класстификации изображений на датасете `ImageNet`. Однако с 2015 года предпринято множество успешных попыток модифицировать архитектуру, и ее различные реализации находятся в рейтинге моделей гораздо выше оригинала.

## DenseNet

`DenseNet` (*Densely Connected Convolutional Network*) была предложена в 2017 году в статье [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993v5.pdf). Успех `ResNet` (*Deep Residual Network*) позволил предположить, что укороченное соединение в CNN позволяет обучать более глубокие и точные модели. Авторы проанализировали это наблюдение и представили компактно соединенный (_dense_) блок - все слои (с соответствующими размерами карты признаков) соединены напрямую друг с другом, то есть каждый слой получает дополнительные входные данные от всех предыдущих слоев и передает свои собственные карты признаков всем последующим слоям. 

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/dense_block.png" width="400" />
</div></br>
<div align="center">
  <figcaption>Рис. 5. <i>Dense block </i> </figcaption>
</div></br>

Важно отметить, что, в отличие от `ResNet`, признаки, прежде чем они будут переданы в следующий слой, не суммируются, а конкатенируются в единый тензор. При этом количество параметров сети DenseNet намного меньше, чем у сетей с такой же точностью работы. Авторы утверждают, что `DenseNet` работает особенно хорошо на малых наборах данных.

Если общее количество соединений в архитектуре более ранних сетей равно количеству слоев _L_, то, поскольку в `DenseNet` каждый слой связан со всеми предыдущими, количество соединений представленной архитектуре равно _L * (L + 1) / 2_.

Благодаря использованию конкатенации карт признаков, количество параметров архитектуры `DenseNet` меньше, чем в более ранних архитектурах с аналогичным количеством слоев, в которых каждый слой читает состояние из предыдущего слоя и записывает на следующий. Фактически, количество параметров `ResNet` велико, потому что у каждого слоя есть свои веса, которые нужно обучать. Вместо этого слои `DenseNet` очень узкие (например, 12 фильтров), и они просто добавляют небольшой набор новых карт признаков. Иными словами, `DenseNet` хранит большую часть карт признаков с предыдущих слоев неизмененной, а часть дополняет "новыми знаниями", поэтому классификатор имеет возможность принимать решение, опираясь на информацию, полученную на каждом из слоев. Таким образом, основная мощь этой архитектуры состоит в повторном использовании карт признаков, которые не изменяются от слоя к слою, а дополняются новой информацией. Выразить выход _Dense_-блока можно следующим образом:
<div align="center">
  
  _H(x<sub>n</sub>) = R([х<sub>0</sub>, x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n-1</sub>])_
  
</div>

На настоящий момент `DenseNet-121` занимает 426 место в соревновании по классификации изображений на датасете `ImageNet`, более глубокий аналог `DenseNet-169` занял 399 место, `DenseNet-201` поднялся на 370 место, `DenseNet-264` - на 362.


## EfficientNet

Долгое время для повышения качества работы нейронной сети применяли методы масштабирования, в частности, изменения глубины сети (количества слоев) и ее ширины (количество фильтров в каждом слое). Таким образом, например, сеть `VGG-16` показывает результаты хуже, чем `VGG-19`, и сеть `ResNet-152` справляется с задачей классификации лучше, чем `ResNet-18`. Архитектуры `WideResNet` и `MobileNets` можно масштабировать по количеству фильтров в слое, то есть в ширину. Однако существует еще одно измерение, масштабирование которого может привести к улучшению качества работы сверточной нейронной сети - разрешение входного изображения. 

В статье [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946v5.pdf) авторы предлагают подход масштабирования сети по всем трем измерениям и показывают, что одновременное увеличение параметров сети может привести к лучшему результату, чем изменение одного измерения. 

Один сверточный _i_-ый слой нейронной сети можно выразить следующим способом:

<div align="center">
  
  _Y<sub>i</sub> = F<sub>i</sub>(X<sub>i</sub>)_
  
</div>

где:

_i_ - номер слоя в сети,

_X_ - входящий тензор размера  _<H<sub>i</sub>, W<sub>i</sub>, C<sub>i</sub>>_

_Y_ - итоговый тензор,

_F_ - оператор преобразования (свертка),


Тогда вся нейронная сеть с _k_ слоями может быть представлена:

<div align="center">
  
  _N = F<sub>k</sub> ⊙ ... ⊙ F<sub>2</sub> ⊙ F<sub>1</sub>(X<sub>1</sub>)_ = ⨀ _<sub>j=1...k</sub> F<sub>j</sub> (X<sub>1</sub>)_
  
</div>

На практике уровни сверточной нейронной сети часто разделены на несколько этапов, и все уровни на каждом этапе имеют одну и ту же архитектуру: например, `ResNet` имеет пять этапов, и все слои на каждом этапе имеют один и тот же сверточный тип, за исключением первого уровеня, который выполняет понижающую дискретизацию. Следовательно, мы можем определить сверточную нейронную сеть как:

**(1)**

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/formula1.png" width="200" />
</div></br>


где _F<sub>i</sub><sup>L<sub>i</sub></sup>_ означает, что на _i_-ом слое преобразование _F_ повторяется _L<sub>i</sub>_ раз, а  _X<sub><H<sub>i</sub>,W<sub>i</sub>,C<sub>i</sub>></sub>_ - это входной тензор _i_-го слоя с высотой _H_, шириной _W_ и количеством каналов _С_.

Обычно разработка новых нейросетевых алгоритмов сопровождается изменением архитектуры слоев _F_, в то время как масштабирование модели сосредотачивается на изменении параметров сети - ее глубины (_L<sub>i</sub>_), ширины (_W<sub>i</sub>_) и разрешения (H<sub>i</sub>, W<sub>i</sub>) без изменения самого слоя _F<sub>i</sub>_. За счет фиксации архитектуры _F<sub>i</sub>_, масштабирование упрощает проблему проектирования модели для новых ограничений вычислительных ресурсов, но по-прежнему остается большое пространство для исследования различных _L<sub>i</sub>_, _C<sub>i</sub>_, _H<sub>i</sub>_, _W<sub>i</sub>_ для каждого уровня. Чтобы уменьшить пространство для поиска оптимальных параметров, авторы ограничивают масштабирование всех слоев равномерно с постоянным соотношением. Итоговая цель - подобрать такие параметры для сети, чтобы точность модели при заданной архитектуре и ресурсах была максимальна:

**(2)**

<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/formula2.png" width="400" />
</div></br>

где где _w_, _d_, _r_ - коэффициенты масштабирования ширины, глубины и разрешения сети;  _F<sub>i</sub>, L<sub>i</sub>, H<sub>i</sub>, W<sub>i</sub>, C<sub>i</sub>_ - предварительно определенные параметры сети.

Как уже было сказано, увеличение глубины сети (_d_) - один из основных и часто используемых способов улучшения качества работы нейронной сети. Чем глубже нейронная сеть, тем более высокоуровневые признаки она может распознавать. С глубиной модели также увеличивается и обобщающая способность сети. Однако чем больше слоев в модели, тем сложнее ее обучать (проблема исчезающего градиента дает о себе знать). Есть несколько способов борьбы с возникающими проблемами во время обучения, такие как нормализация батчей, *skip connections* в `ResNet` и _Dense Block_ в `DenseNet`, однако даже с применением этих средств точность классификации перестает увеличиваться: например, в среднем итоговое качество `ResNet-101` примерно такое же, как у сети `ResNet-1000`. 

Масштабирование нейронной сети в ширину (_w_) часто используется в моделях небольшого размера. "Широкие" сети, как правило, способны улавливать мелкие признаки и их легче обучать. Однако в очень широких, но неглубоких сетях часто возникают трудности с распознаванием высокоуровневых признаков. 

С входными изображениями высокого разрешения (_r_) сверточные нейронные сети потенциально могут захватывать более мелкие признаки. Начиная с 224x224 в ранних сверточных сетях, современные, как правило, используют 299x299 или 331x331 для достижения большей точности. В 2018 году модель `GPipe` ([Huang et al., 2018](https://arxiv.org/pdf/1811.06965v5.pdf)) достигла высочайшего уровня точности классификации на датасете `ImageNet` с разрешением 480x480 - 97 место, 84.4% top 1 и 97% top 5. Более высокие разрешения, такие как 600x600, также широко используются в сверточных нейронных сетях для решения задачи детекции объектов.

Авторы статьи [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946v5.pdf) эмпирически показывают, что масштабирование нейросетевой модели с различным коэффициентом глубины _d_ приводит к увеличению точности классификации до определенного порога, а затем увеличение количества слоев перестает положительно влиять на итоговый результат. Увеличение ширины модели _w_ влияет на результат работы сети схожим образом - после достижения определенного результата качество перестает расти. Более высокое разрешение входного изображения _r_ улучшает итоговую точность классификации, но выигрыш в точности уменьшается для очень высоких разрешений (_r_ = 1.0 означает разрешение 224x224, а _r_ = 2.5 означает разрешение 560x560).


<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/figure3.png" width="700" />
</div></br>
<div align="center">
  <figcaption>Рис. 6. <i>Масштабирование базовой модели с различными коэффициентами ширины (w), глубины (d) и разрешения (r) сети. Более тяжелые сети, как правило, обеспечивают более высокую точность, но прирост качества быстро перестает увеличиваться после достижения 80%, демонстрируя ограничения одномерного масштабирования. </i> </figcaption>
</div></br>

*Таким образом, увеличение значения параметров сети - ширины, глубины или разрешения - повышает точность, но прирост качества уменьшается с увеличением размера модели.*

Авторы пришли к выводу, что разные масштабные измерения не являются независимыми. Интуитивно понятно, что для изображений с более высоким разрешением мы должны увеличить глубину сети, чтобы большие воспринимающие поля могли помочь распознать признаки, которые включают больше пикселей в изображениях более высокого разрешения. По той же причине, необходимо увеличивать ширину сети.

Для того, чтобы оптимально подобрать глубину, ширину сети и разрешение, авторы предлагают использовать _compound scaling method_. В этом методе используется составной коэффициент _φ_ для равномерного масштабирования ширины, глубины и разрешения сети следующим образом образом:

**(3)**

<div align="center">
  
  _depth: d = α<sup>φ</sup>_
  
  _width: w = β<sup>φ</sup>_
  
  _resolution: r = γ<sup>φ</sup>_
  
  _α · β<sup>2</sup> · γ<sup>2</sup> ≈ 2_
  
  _α ≥ 1, β ≥ 1, γ ≥ 1_
  
</div>

где α, β, γ - константы, которые могут быть найдены с помощью поиска по сетке (_grid search_). Коэффициент _φ_ - это задаваемый пользователем коэффициент, который контролирует, сколько дополнительных ресурсов доступно для масштабирования модели, в то время как _α, β, γ_ определяют, как назначить эти дополнительные ресурсы ширине, глубине и разрешению сети соответственно.

Примечательно, что количество операций [FLOPS](https://ru.wikipedia.org/wiki/FLOPS) обычной свертки пропорционально d, w<sup>2</sup>, r<sup>2</sup>, т.е. увеличение глубины сети в два раза удвоит количество операций FLOPS, но увеличение ширины или разрешения сети в два раза увеличит количество операций FLOPS в четыре раза.

Масштабирование моделей семейств `MobileNets` и `ResNets` с помощью использования _compound scaling method_ показало значительное увеличение качества классификации по сравнению с оригинальными архитектурами и масштабированными по одному измерению. Обучение и сравнение результатов осуществлялось на датасете `ImageNet`.

<div align="center">
  <figcaption>Таблица 1. <i>Результаты масштабирования моделей семейств MobileNets и ResNets </i> </figcaption>
</div></br>
<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/table3.png" width="600" />
</div></br>


В этой же статье предложено семейство архитектур сверточных нейронных сетей `EfficientNet`. Целью авторов являлось не только увеличение точности итоговой модели, но и FLOPS, то есть функция оптимизации выглядит следующим образом:

<div align="center">
  
  _ACC(m)×[FLOPS(m)/T]<sup>w</sup>_
  
</div>

где _ ACC(m)_ - точность модели _m_, _FLOPS(m)_ - количество операций с плавающей запятой, осуществляемое моделью _m_, _T_ - целевое количество операций (в данной работе -  400M), а _w_=-0.07 - гиперпараметр для управления FLOPS и ACC. Архитектура `EfficientNet` аналогична [MnasNet](https://paperswithcode.com/paper/mnasnet-platform-aware-neural-architecture), но несколько тяжелее.

<div align="center">
  <figcaption>Таблица 2. <i>Архитектура сети EfficientNet-B0 </i> </figcaption>
</div></br>
<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/table1.png" width="600" />
</div></br>


Инвертированный остаточный блок, иногда называемый `MBConv`-блоком, представляет собой тип остаточного блока, используемый для моделей, которые используют инвертированную структуру по соображениям эффективности. Первоначально он был предложен для архитектуры сверточной нейронной сети [MobileNetV2](https://arxiv.org/pdf/1801.04381v4.pdf). С тех пор он был повторно использован для нескольких оптимизированных CNN для мобильных устройств.
Традиционный остаточный блок имеет _wide -> narrow -> wide_ структуру по количеству каналов. Вход имеет большое количество каналов, которые сжимаются с помощью свертки 1x1. Затем количество каналов снова увеличивается.

Напротив, инвертированный остаточный блок (`MBConv`) использует подход _narrow -> wide -> narrow_, отсюда и в названии слово _инверсионный_. Сначала используется свертка 1x1 для сокращения количества каналов, затем [свертка 3x3 по глубине](https://paperswithcode.com/method/depthwise-convolution) (что значительно сокращает количество параметров), и в конце снова свертка 1x1. 

Схематично `MBConv`-блок выглядит следующим образом:

```
nn.Sequential(
  # narrow -> wide
  Conv1X1BnReLU(in_features, 
                expanded_features,
                act=nn.ReLU6),
                
  # wide -> wide
  Conv3X3BnReLU(expanded_features,
                expanded_features, 
                groups=expanded_features,
                act=nn.ReLU6),
                        
  # wide -> narrow
  Conv1X1BnReLU(expanded_features, out_features, act=nn.Identity)
```

_Масштабирование архитектуры происходит в два этапа:_

- Фиксируется _φ = 1_ и с помощью поиска по сетке (_grid search_) на основании (1) и (2) ищутся оптимальные _α, β, γ_. Для `EfficientNet-B0` найдены параметры: _α = 1.2, β = 1.1, γ = 1.15_, при ограничении _α · β<sup>2</sup> · γ<sup>2</sup> ≈ 2_ ;

- Фиксируются _α, β, γ_ как константы и базовая модель масштабируется с другим _φ_ с учетом (3), чтобы получить модели `EfficientNet-B1` до `B7` (подробности в таблице 2)

Эмпирически показано, что масштабирование сети `EfficientNet-B0` с использованием _compound scaling method_ приводит к более высоким результатам, чем масштабирование по одному измерению - глубине, ширине или разрешению. Все методы масштабирования повышают точность за счет увеличения количества FLOPS, но использование _compound scaling method_ может еще больше повысить точность до 2,5% по сравнению с другими методами масштабирования одного измерения, что свидетельствует о его эффективности.

<div align="center">
  <figcaption>Таблица 3. <i>Итоговое качество масштабированной разными способами модели EfficientNet-B0 </i> </figcaption>
</div></br>
<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/table7.png" width="600" />
</div></br>

Обучение моделей `EfficientNet` осуществлялось с использованием оптимизатора `RMSProp` (_decay_ = 0.9, _momentum_ = 0.9), начальной скоростью обучения 0.256, которая уменьшалась на 0.97 каждые 2.4 эпохи. В качестве функции активации использовалась `SiLU`. Сравнение существующих архитектур с `EfficientNet` показало превосходство новой модели.

<div align="center">
  <figcaption>Таблица 4. <i>Результаты тестирования моделей EfficientNet на датасете ImageNet. Все модели EfficientNet масштабируются из базовой модели EfficientNet-B0 с использованием разных коэффициентов &phi; с учетом (3). Сети с аналогичной точностью сгруппированы вместе для сравнения эффективности. По сравнению с существующими архитектурами, модели EfficientNet обладают в меньшим количеством параметров и FLOPS </i> </figcaption>
</div></br>
<div align="center">
  <img src="https://github.com/kontik-pk/diplom/blob/main/nets/convolutional/illustrations/table2.png" width="1000" />
</div></br>


Таким образом, существует 8 реализаций `EfficientNet`, от самого простого `B0` до `B7` по мере увеличения сложности архитектуры. Тем не менее, даже самый простой `EfficientNet-B0` показывает хорошие результаты. При наличии всего лишь 5,3 миллионов параметров, он обеспечивает точность 77,1% (Top-1), поэтому дообучение (_fine-tuning_) модели машинного обучения не займет много времени.

На настоящий момент, сети семества `EfficientNet` находятся в топе соревнования по классификации изображений на датасете `ImageNet`: EfficientNet-B0 - 394 место, `EfficientNet-B7` - 87 место. Продолжают выходить новые вариации архитектуры, которые показывают лучшее качество, например, модель [EfficientNet-L2-475](https://arxiv.org/pdf/2010.01412v3.pdf), занимающая 12 место.

# Резюме

Исходя из всего вышесказанного, можно составить сводную таблицу по используемым в работе архитектурам:

| Архитектура       | Год публикации     | Количество параметров | Особенность архитектуры | Место на ImageNet  | top-1  | top-5 |
|:-----------------:|:------------------:|:---------------------:|:-----------------------:|:------------------:|:------:|:-----:|
| VGG-19            |       2014         |         144M          |            -            |          436       | 74.5%  | 92.0% |
| DenseNet-161      |       2017         |          26M          |       Dense blocks      |          347       | 78.44% |   -   |
| ResNet-152        |       2015         |          60M          |     Residual blocks     |          342       | 78.57% | 94.3% |
| EfficientNet-B6   |       2019         |          43M          |     Compound scaling    |          116       | 84.00% | 96.9% |


# Источники

- [Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556v6.pdf)
- [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385v1.pdf)
- [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993v5.pdf)
- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946v5.pdf)
- [GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism](https://arxiv.org/pdf/1811.06965v5.pdf)
- [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://paperswithcode.com/paper/mnasnet-platform-aware-neural-architecture)
- [MobileNetV2](https://arxiv.org/pdf/1801.04381v4.pdf)
- https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a
- https://towardsdatascience.com/residual-bottleneck-inverted-residual-linear-bottleneck-mbconv-explained-89d7b7e7c6bc
- https://medium.com/@bigdataschool
- https://neurohive.io/ru/vidy-nejrosetej/resnet-34-50-101/
- https://habr.com/ru/post/498168
- https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec
- https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035
