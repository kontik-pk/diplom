## VGG

`VGG-19` — сверточная нейронная сеть (CNN), которая имеет 19 главных слоев (16 сверточных, 3 полносвязных) а также 5 слоев `MaxPool` и 1 слой `SoftMax`. Она была сконструирована и обучена в Оксфордском университете в 2014 году. Для обучения сети VGG-19 использовалось более чем 1 миллиона изображений из базы данных `ImageNet`. Эта предварительно обученная сеть может классифицировать до 1000 объектов.

Сеть VGG впервые представлена в [этой статье](https://arxiv.org/pdf/1409.1556v6.pdf). Авторы экспериментировали с глубиной сверточной сети и изучали влияние количества слоев в сети на итоговое качество классификации. На вход сетям подавались изображения 224 × 224 пикселя RGB. Единственная предварительная обработка - это вычитание из каждого пикселя среднего значения RGB, вычисленного на обучающем наборе. Каждое изображение проходило через сверточные слои, размер свертки составлял 3×3 пикселя, шаг свертки - 1 пиксель. 
За сверточными слоями следует три полносвязных слоя. Первые два содержат по 4096 нейронов, а последний - 1000 нейронов (по количеству определяемых классов). Архитектура сети завершается слоем `SoftMax`. В качестве функции активации используется `ReLU`.

Обучение сети осуществлялось с помощью градиентного спуска, размер батча составлял 256 изображений. Скорость обучения изначально установлена 10^2, но уменьшалась в 10 раз, как только качество классифкации на валидационной выборке переставало улучшаться. Скорость обучения уменьшалась 3 раза, а обучение остановлено на 74 эпохах. 

Авторами исследовались сети глубиной 11, 13, 16 и 19 слоев. Лучшие результаты показала самая глубокая сеть.

В настоящий момент, сеть `VGG-19` занимает 436 место по качеству классификации на датасете `ImageNet` (top 1 accuracy - 74.5%, top 5 accuracy -	92.0%). Рейтинг доступен [здесь](https://paperswithcode.com/sota/image-classification-on-imagenet).

## ResNet

ResNet — сокращенное название для Residual Network (дословно  — «остаточная сеть»). Сеть ResNet была разработана в Microsoft в 2015 году для решения задачи распознавания изображений. Эта модель также обучена на более чем 1 миллионе изображений из базы данных `ImageNet`. ResNet может классифицировать до 1000 объектов, принимает на вход цветные изображения размером 224×224 пикселей. Данная сеть была разработана с целью избавиться от затухающих и взрывных градиентов.

[Статья](https://arxiv.org/pdf/1512.03385v1.pdf), в которой представлена сеть `ResNet` начинается с вопроса о том, всегда ли увеличение глубины сети приводит к лучшему результату. Ответ на этот вопрос, конечно, отрицательный, поскольку увеличение количества слоев приводит к проблеме затухающих/взрывающихся градиентов. Из-за этого обучение глубоких сетей затрудняется - поскольку градиент распространяется обратно на более ранние слои, повторное умножение может сделать градиент бесконечно малым. В результате, по мере того, как сеть углубляется, качество классификации начинает быстро ухудшаться. Для решения данной проблемы, авторы предлагают использовать *остаточное обучение*, основная особенность которого - использование *остаточных блоков* (*Residual blocks*) в архитектуре модели.

Нейронная сеть ResNet-152, представленная в 2015 году, в настоящий момент занимает 339 место в соревновании по класстификации изображений на датасете `ImageNet`. Однако с 2015 года предпринято множество успешных попыток модифицировать архитектуру, и ее различные реализации находятся в рейтинге моделей гораздо выше оригинала.

### Residual blocks

При увеличении количества слоев в нейронной сети, качество обучения растет до определенного момента, а потом начинает уменьшаться. Причиной этому может быть как переобучение (нейросеть "запоминает" признаки, что приводит к великолепным результатам на обучающей выборке, и к ухудшению качества на валидационной), так и затухание градиента. Авторы [статьи](https://arxiv.org/pdf/1512.03385v1.pdf) также показали, что более глубокие сети могут обучаться хуже, чем неглубокие. Такую проблему деградации можно решить, модифицировав процесс обучения. Архитектуры сетей до появления `ResNet` представляли собой последовательность слоев, через которые пропускается исходное изображение. После того, как исходное изображение пропустится через один слой, результат преобразования отправляется дальше, к следующему слою, и так далее. 
Идея `residual blocks` основана на том, чтобы сохранять "остаточную" информацию перед переходом к следующим слоям. Например, назовем входную матрицу `x`, а наша цель - найти оптимальное распределение весов в свертке `H(x)`. Тогда разница между входом и выходом (или остаток) будет:
```
R(x) = Output — Input = H(x) — x
```
А искомое распределение

```
H(x) = R(x) + x
```

На настоящий момент `DenseNet-121` занимает 426 место в соревновании по классификации изображений на датасете `ImageNet`, более глубокий аналог `DenseNet-169` занял 399 место, `DenseNet-201` поднялся на 370 место, `DenseNet-264` - 362.


## DenseNet

DenseNet (Densely Connected Convolutional Network) была предложена в 2017 году в статье [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993v5.pdf). Успех ResNet (Deep Residual Network) позволил предположить, что укороченное соединение в CNN позволяет обучать более глубокие и точные модели. Авторы проанализировали это наблюдение и представили компактно соединенный (dense) блок - все слои (с соответствующими размерами карты признаков) соединены напрямую друг с другом, то есть каждый слой получает дополнительные входные данные от всех предыдущих слоев и передает свои собственные карты признаков всем последующим слоям. Важно отметить, что, в отличие от ResNet, признаки, прежде чем они будут переданы в следующий слой, не суммируются, а конкатенируются в единый тензор. При этом количество параметров сети DenseNet намного меньше, чем у сетей с такой же точностью работы. Авторы утверждают, что DenseNet работает особенно хорошо на малых наборах данных.

Если общее количество соединений в архитектуре более ранних сетей равно количеству слоев `L`, то, поскольку в `DenseNet` каждый слой связан со всеми предыдущими, количество соединений представленной архитектуре равно `L * (L + 1) / 2`.

Благодаря использованию конкатенации карт признаков, количество параметров архитектуры `DenseNet` меньше, чем в более ранних архитектурах с аналогичным количеством слоев, в которых каждый слой читает состояние из предыдущего слоя и записывает на следующий. Фактически, количество параметров ResNets велико, потому что у каждого слоя есть свои веса, которые нужно обучать. Вместо этого слои `DenseNet` очень узкие (например, 12 фильтров), и они просто добавляют небольшой набор новых карт признаков. Иными словами, `DenseNet` хранит большую часть карт признаков с предыдущих слоев неизмененной, а часть дополняет "новыми знаниями", поэтому классификатор имеет возможность принимать решение, опираясь на информацию, полученную на каждом из слоев. Таким образом, основная мощь этой архитектуры состоит в повторном использовании карт признаков, которые не изменяются от слоя к слою, а дополняются новой информацией. Выразить выход Dense-блока можно следующим образом:

H(x<sub>n</sub>) = R([х<sub>0</sub>, x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n-1</sub>])



## EfficientNet

Долгое время для повышения качества работы нейронной сети применяли методы масштабирования, в частности, изменения глубины сети (количества слоев) и ее ширины (количество фильтров в каждом слое). Таким образом, например, сеть VGG-16 показывает результаты хуже, чем VGG-19, и сеть ResNet-152 справляется с задачей классификации лучше, чем ResNet-18. Архитектуры `WideResNet` и `MobileNets` можно масштабировать по количеству фильтров в слое, то есть в ширину. Однако существует еще одно измерение, масштабирование которого может привести к улучшению качества работы сверточной нейронной сети - разрешение входного изображения. 

В статье [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946v5.pdf) авторы предлагают подход масштабирования сети по всем трем измерениям и показывают, что одновременное увеличение параметров сети может привести к лучшему результату, чем изменения одного измерения. 

Один сверточный _i_-ый слой нейронной сети можно выразить следующим способом:

<div align="center">
  
  _Y<sub>i</sub> = F<sub>i</sub>(X<sub>i</sub>)_
  
</div>

где:

_i_ - номер слоя в сети,

_X_ - входящий тензор размера  _<H<sub>i</sub>, W<sub>i</sub>, C<sub>i</sub>>_

_Y_ - итоговый тензор,

_F_ - оператор преобразования (свертка),


Тогда вся нейронная сеть с _k_ слоями может быть представлена:

<div align="center">
  
  _N = F<sub>k</sub> ⊙ ... ⊙ F<sub>2</sub> ⊙ F<sub>1</sub>(X<sub>1</sub>)_ = ⨀ _<sub>j=1...k</sub> F<sub>j</sub> (X<sub>1</sub>)_
  
</div>

На практике уровни светточной нейронной сети часто разделены на несколько этапов, и все уровни на каждом этапе имеют одну и ту же архитектуру: например, `ResNet` имеет пять этапов, и все слои на каждом этапе имеют один и тот же сверточный тип, за исключением первого уровеня, который выполняет понижающую дискретизацию. Следовательно, мы можем определить сверточную нейронную сеть как:

**ФОРМУЛА 1**

где _F<sub>i</sub><sup>L<sub>i</sub></sup>_ означает, что на _i_-ом слое преобразование _F_ повторяется _L<sub>i</sub>_ раз, а  _X<sub><H<sub>i</sub>,W<sub>i</sub>,C<sub>i</sub>></sub>_ - это входной тензор _i_-го слоя с высотой _H_, шириной _W_ и количеством каналов _С_.

Обычно разработка новых нейросетевых алгоритмов сопровождается изменением архитектуры слоев _F_, в то время как масштабирование модели сосредотачивается на изменении параметров сети - ее глубины (_L<sub>i</sub>_), ширины (_W<sub>i</sub>_) и разрешения (H<sub>i</sub>, W<sub>i</sub>) без изменения самого слоя _F<sub>i</sub>_. За счет фиксации архитектуры _F<sub>i</sub>_, масштабирование упрощает проблему проектирования модели для новых ограничений вычислительных ресурсов, но по-прежнему остается большое пространство для исследования различных _L<sub>i</sub>_, _C<sub>i</sub>_, _H<sub>i</sub>_, _W<sub>i</sub>_ для каждого уровня. Чтобы уменьшить пространство для поиска оптимальных параметров, авторы ограничивают масштабирование всех слоев равномерно с постоянным соотношением. Итоговая цель - подобрать такие параметры для сети, чтобы точность модели при заданной архитектуре и ресурсах была максимальна:


**ФОРМУЛА 2**

где где _w_, _d_, _r_ - коэффициенты масштабирования ширины, глубины и разрешения сети;  _F<sub>i</sub>, L<sub>i</sub>, H<sub>i</sub>, W<sub>i</sub>, C<sub>i</sub>_ - предварительно определенные параметры сети.

Как уже было сказано, увеличение глубины сети (_d_) - один. из основных и часто используемых способов улучшения качества работы нейронной сети. Чем глубже нейронная сеть, тем более высокоуровневые признаки она может распознавать. С глубиной модели также увеличивается и обобщающая способность сети. Однако чем больше слоев в модели, тем сложнее ее обучать (проблема исчезающего градиента дает о себе знать). Есть несколько способов борьбы с возникающими проблемами во время обучения, такие как нормализация батчей, skip connections в ResNet и Dense Block в DenseNet, однако даже с применением этих средств точность классификации перестает увеличиваться: например, в среднем итоговое качество ResNet-101 примерно такое же, как у сети ResNet-1000. 

Масштабирование нейронной сети в ширину (_w_) часто используется в моделях небольшого размера. "Широкие" сети, как правило, способны улавливать мелкие признаки и их легче обучать. Однако в очень широких, но неглубоких сетях часто возникают трудности с распознаванием высокоуровневых признаков. 

С входными изображениями высокого разрешения (_r_) сверточные нейронные сети потенциально могут захватывать более мелкие признаки. Начиная с 224x224 в ранних сверточных сетях, современные, как правило, используют 299x299 или 331x331 для достижения большей точности. В 2018 году модель `GPipe` (Huang et al., 2018) достигла высочайшего уровня точности классификации на датасете `ImageNet` с разрешением 480x480 - 97 место, 84.4% top 1 и 97% top 5. Более высокие разрешения, такие как 600x600, также широко используются в сверточных нейронных сетях для решения задачи детекции объектов.

Авторы статьи [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946v5.pdf) эмпирически показывают, что масштабирование нейросетевой модели с различным коэффициентом глубины _d_ приводит к увеличению точности классификации до определенного порога, а затем увеличение количества слоев перестает положительно влиять на итоговый результат. Увеличение ширины модели _w_ влияет на результат работы сети схожим образом - после достижения определенного результата качество перестает расти. Более высокое разрешение входного изображения _r_ улучшает итоговую точность классификации, но выигрыш в точности уменьшается для очень высоких разрешений (_r_ = 1.0 означает разрешение 224x224, а _r_ = 2.5 означает разрешение 560x560).

**График исследований w r d**

*Таким образом, увеличение параметров сети - ширины, глубины или разрешения - повышает точность, но прирост качества уменьшается с увеличением размера модели.*

Авторы пришли к выводу, что разные масштабные измерения не являются независимыми. Интуитивно понятно, что для изображений с более высоким разрешением мы должны увеличить глубину сети, чтобы более крупные воспринимающие поля могли помочь распознать признаки, которые включают больше пикселей в изображениях более высокого разрешения. По той же причине, необходимо увеличивать ширину сети.

Для того, чтобы оптимально подобрать глубину, ширину сети и разрешение, авторы предлагают использовать _compound scaling method_. В этом методе используется составной коэффициент _φ_ для равномерного масштабирования ширины, глубины и разрешения сети следующим образом образом:

**(3)**

<div align="center">
  
  _depth: d = α<sup>φ</sup>_
  
  _width: w = β<sup>φ</sup>_
  
  _resolution: r = γ<sup>φ</sup>_
  
  _α · β<sup>2</sup> · γ<sup>2</sup> ≈ 2_
  
  _α ≥ 1, β ≥ 1, γ ≥ 1_
  
</div>

где α, β, γ - константы, которые могут быть найдены с помощью поиска по сетке (_grid search_). Коэффициент _φ_ - это задаваемый пользователем коэффициент, который контролирует, сколько дополнительных ресурсов доступно для масштабирования модели, в то время как _α, β, γ_ определяют, как назначить эти дополнительные ресурсы ширине, глубине и разрешению сети соответственно.

Примечательно, что количество операций [FLOPS](https://ru.wikipedia.org/wiki/FLOPS) обычной свертки пропорционально d, w<sup>2</sup>, r<sup>2</sup>, т.е. увеличение глубины сети в два раза удвоит количество операций FLOPS, но увеличение ширины или разрешения сети в два раза увеличит количество операций FLOPS в четыре раза.

Масштабирование моделей семейств `MobileNets` и `ResNets` с помощью использования _compound scaling method_ показало значительное увеличение качества классификации по сравнению с оригинальными архитектурами и масштабированными по одному измерению. Обучение и сравнение результатов осуществлялось на датасете `ImageNet`.

**Table 3. Scaling Up MobileNets and ResNet**

В этой же статье предложено семейство архитектур сверточных нейронных сетей `EfficientNet`. Целью авторов являлось не только увеличение точности итоговой модели, но и FLOPS, то есть функция оптимизации выглядит следующим образом:

<div align="center">
  
  _ACC(m)×[FLOPS(m)/T]<sup>w</sup>_
  
</div>

где _ ACC(m)_ - точность модели _m_, _FLOPS(m)_ - количество операций с плавающей запятой, осуществляемое моделью _m_, _T_ - целевое количество операций (зависит от ресурсов, в данной работе -  400M), а _w_=-0.07 - гиперпараметр для управления FLOPS и ACC. Архитектура `EfficientNet` аналогична [MnasNet](https://paperswithcode.com/paper/mnasnet-platform-aware-neural-architecture), но несколько тяжелее.

**Table 1. EfficientNet-B0 baseline network**

Инвертированный остаточный блок, иногда называемый `MBConv`-блоком, представляет собой тип остаточного блока, используемый для моделей, которые используют инвертированную структуру по соображениям эффективности. Первоначально он был предложен для архитектуры сверточной нейронной сети [MobileNetV2](https://arxiv.org/pdf/1801.04381v4.pdf). С тех пор он был повторно использован для нескольких оптимизированных CNN для мобильных устройств.
Традиционный остаточный блок имеет _wide -> narrow -> wide_ структуру по количеству каналов. Вход имеет большое количество каналов, которые сжимаются с помощью свертки 1x1. Затем количество каналов снова увеличивается.

Напротив, инвертированный остаточный блок (`MBConv`) использует подход _narrow -> wide -> narrow_, отсюда и в названии слово _инверсионный_. Сначала используется свертка 1x1 для сокращения количества каналов, затем [свертка 3x3 по глубине](https://paperswithcode.com/method/depthwise-convolution) (что значительно сокращает количество параметров), и в конце снова свертка 1x1. 

Схематично `MBConv`-блок выглядит следующим образом:

```
nn.Sequential(
  # narrow -> wide
  Conv1X1BnReLU(in_features, 
                expanded_features,
                act=nn.ReLU6),
                
  # wide -> wide
  Conv3X3BnReLU(expanded_features,
                expanded_features, 
                groups=expanded_features,
                act=nn.ReLU6),
                        
  # wide -> narrow
  Conv1X1BnReLU(expanded_features, out_features, act=nn.Identity)
```

_Масштабирование архитектуры происходит в два этапа:_

- Фиксируется _φ = 1_ и с помощью поиска по сетке (_grid search_) на основании (1) и (2) ищутся оптимальные _ α, β, γ_. Для `EfficientNet-B0` найдены параметры: _α = 1.2, β = 1.1, γ = 1.15_, при ограничении _α · β<sup>2</sup> · γ<sup>2</sup> ≈ 2_ ;

- Фиксируются _α, β, γ_ как константы и базовая модель масштабируется с другим _φ_, используя уравнение 3, чтобы получить модели `EfficientNet-B1` до `B7` (подробности в таблице 2)

Существует 8 реализаций `EfficientNet`, отсчитывающихся от `B0` до `B7` по мере увеличения сложности архитектуры. Тем не менее, даже самый простой `EfficientNetB0` показывает хорошие результаты. При наличии всего лишь 5,3 миллионов параметров, он обеспечивает точность 77,1% (Top-1), поэтому дообучение (fine-tuning) модели машинного обучения не займет много времени.



# Источники

- [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION](https://arxiv.org/pdf/1409.1556v6.pdf)
- [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385v1.pdf)
- [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993v5.pdf)
- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946v5.pdf)
- [GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism](https://arxiv.org/pdf/1811.06965v5.pdf)
- [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://paperswithcode.com/paper/mnasnet-platform-aware-neural-architecture)
- [MobileNetV2](https://arxiv.org/pdf/1801.04381v4.pdf)
- https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a
- https://towardsdatascience.com/residual-bottleneck-inverted-residual-linear-bottleneck-mbconv-explained-89d7b7e7c6bc
- https://medium.com/@bigdataschool
- https://neurohive.io/ru/vidy-nejrosetej/resnet-34-50-101/
- https://habr.com/ru/post/498168
- https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec
- https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035
